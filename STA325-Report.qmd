---
title: "STA325 Case Study"
author: "Chase Mathis"
format: pdf
execute: 
  warning: false
  echo: false
editor: visual
---

## Packages/Data

```{r}
#| echo: true
library(tidyverse) # datawrangling
library(tidymodels) #modeling steps
library(knitr) # nice output
library(boot)
library(patchwork)

ggplot2::theme_set(ggplot2::theme_minimal())

train <- read_csv("data/data-train.csv")
test <- read_csv("data/data-test.csv")
```

```{r}
## mutate data so that we get central moments
centralTrain <- train |> 
  mutate(mean = R_moment_1,
         variance = R_moment_2 - R_moment_1^2,
         skewness = R_moment_3 -3*R_moment_1*R_moment_2 + 2*R_moment_1^3,
         kurtosis = R_moment_4 - 4*R_moment_1*R_moment_3 + 6*R_moment_2*R_moment_1^2 - 3*R_moment_1^4) |> 
  select(-contains("R_"))
```

#### Investigating Relationship Between Mean and Froude's Number

```{r}
centralTrain |> 
  count(Fr) |> 
  kable(col.names = c("Froude's Number", "Count"), caption = "Distribution of Froude's Number")
```

Similar to Reynolds number, this number is somewhat non-continuous as there is only three buckets for the number. Therefore I am going to make it a categorical variable to help interprebaility. For instance, how do we interpret Infinity? Instead I will make

-   0.052 == `Low`

-   0.300 == `Medium`

-   Inf == `Infinity`

```{r}
centralTrain <- centralTrain |> 
  mutate(Fr = case_when(
    Fr < 0.3 ~ "Low",
    Fr == 0.3 ~ "Medium",
    Fr == Inf ~ "Infinity"
  )) |> 
  mutate(Fr = factor(Fr, levels = c("Low", "Medium", "Infinity")))

```

It seems hard to distinguish what affect Froud's number has on the mean from this plot.

## Simple Linear Regression

```{r}
#| label: Baseline-Model
SLRMean <- lm(mean ~ St + Re + Fr, data = centralTrain)
MSE_SLR_Mean <- sum(resid(SLRMean)^2)/nrow(centralTrain)
```

```{r}
SLRVar <- lm(variance ~ St + Re + Fr, data = centralTrain)
MSE_SLR_Var <- sum(resid(SLRVar)^2)/nrow(centralTrain)
```

```{r}
SLRSkew <- lm(skewness ~ St + Re + Fr, data = centralTrain)
MSE_SLR_Skew <- sum(resid(SLRSkew)^2)/nrow(centralTrain)
```

```{r}
SLRKurt <- lm(kurtosis ~ St + Re + Fr, data = centralTrain)
MSE_SLR_Kurt <- sum(resid(SLRKurt)^2)/nrow(centralTrain)
```

```{r}
#| label: Model-Metrics-SLR

SLRModelMetrics <- tribble(~Mean, ~Variance, ~Skewness, ~Kurtosis,
                           MSE_SLR_Mean, MSE_SLR_Var, MSE_SLR_Skew, MSE_SLR_Kurt)

SLRModelMetrics |> 
  kable(caption = "Mean Squared Error using Simple Linear Regression")
```

It is clear that the using a Simple Linear Regression model to predict anything but the `mean` is not a good idea as the performance is not good. Nonetheless it serves as a good baseline for predicting further complex models.

## Inference

### Stokes Number `St`

Stoke's Number quantifies the particle's characteristics i.e. it's size and density. Let's see how this parameter effects the distribution of the final turbulent space.

```{r}
StokesLMMean <- lm(mean ~ St, data = centralTrain)
summary(StokesLMMean)
```

Using a linear model with only Stoke's predictor, we see that the predictor is statistically signifcant for an alpha level of `0.01`. We can interpret it's coefficient as for every one point increase in Stoke's number, the `mean` of the final turbulent distribution increases by about `0.015` .

```{r}
StokesLmVar <- lm(variance ~ St, data = centralTrain)
summary(StokesLmVar)
StokesLmSkew <- lm(variance ~ St, data = centralTrain)
summary(StokesLmSkew)
StokesLmKurt <- lm(kurtosis ~ St, data = centralTrain)
summary(StokesLmKurt)
```

Looking at the summary for a Linear Model predicting the variance of the final distribution with Stoke's Number, we can see that it has essentially no affect on the `variance`, `skewness`, or `kurtosis` of the final system. Overall, this parameter does not seem to have a great impact on the final resulting distribution in general. This can be made clear by visualizing it's relationship:

```{r}
p1 <- ggplot(data = centralTrain, aes(x = St, y = mean)) + geom_point() + 
  labs(
    x = "Stoke's Number",
    y = "Mean",
    title = "Relationship between Stoke's Number and the Mean"
  )
p2 <- ggplot(data = centralTrain, aes(x = St, y = variance)) + geom_point()+ 
  labs(
    x = "Stoke's Number",
    y = "Variance",
    title = "Relationship between Stoke's Number and the Variance"
  )
p3 <- ggplot(data = centralTrain, aes(x = St, y = skewness)) + geom_point()+ 
  labs(
    x = "Stoke's Number",
    y = "Skewness",
    title = "Relationship between Stoke's Number and the Skewness"
  )
p4 <- ggplot(data = centralTrain, aes(x = St, y = kurtosis)) + geom_point()+ 
  labs(
    x = "Stoke's Number",
    y = "Kurtosis",
    title = "Relationship between Stoke's Number and Kurtosis"
  )

(p1 + p2)/(p3 + p4)
```

### Reynold's Number `Re`

Reynold's Number `Re` in our data is a number that quantifies the initial fluid turbulence of the system.

```{r}
ReLM <- lm(mean ~ St, data = centralTrain)
summary(StokesLM)
```

## Prediction

## Random Forests

## Evaluating Our Models

```{r}
ModelMetricsMoment1 <- tribble(~ModelType, ~MSE,
                        "Linear Regression", MSE_SLR)
#ModelMetricsMoment2
```

```{r, warning = FALSE}
set.seed(1)
cv_error <- rep(0,10)
for(i in 1:10){
  fit <- glm(mean ~ poly(St, i, raw = TRUE) + poly(Re, i, raw = TRUE) + Fr, data = centralTrain)
  cv_error[i] <- cv.glm(centralTrain, fit, K = 10)$delta[1]
}
plot(cv_error, type = "b", xlab = "Degree (mean)")
cv_error <- rep(0,10)
for(i in 1:10){
  fit <- glm(variance ~ poly(St, i, raw = TRUE) + poly(Re, i, raw = TRUE) + Fr, data = centralTrain)
  cv_error[i] <- cv.glm(centralTrain, fit, K = 10)$delta[1]
}
plot(cv_error, type = "b", xlab = "Degree (variance)")
cv_error <- rep(0,10)
for(i in 1:10){
  fit <- glm(skewness ~ poly(St, i, raw = TRUE) + poly(Re, i, raw = TRUE) + Fr, data = centralTrain)
  cv_error[i] <- cv.glm(centralTrain, fit, K = 10)$delta[1]
}
plot(cv_error, type = "b", xlab = "Degree (skewness)")
cv_error <- rep(0,10)
for(i in 1:10){
  fit <- glm(kurtosis ~ poly(St, i, raw = TRUE) + poly(Re, i, raw = TRUE) + Fr, data = centralTrain)
  cv_error[i] <- cv.glm(centralTrain, fit, K = 10)$delta[1]
}
plot(cv_error, type = "b", xlab = "Degree (kurtosis)")
```

The optimal degree polynomials for predicting mean, variance, skew, and kurtosis are 2, 2, 4, and 3, respectively.
